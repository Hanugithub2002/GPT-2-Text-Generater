{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKkQpdOtCTFT"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2LMHeadModel,GPT2Tokenizer"
      ],
      "metadata": {
        "id": "9GJoTniSCb_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")"
      ],
      "metadata": {
        "id": "07d2Sv3gCzIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = GPT2LMHeadModel.from_pretrained(\"gpt2-large\",pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "T2fK4ucnDKrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'The internet is a'"
      ],
      "metadata": {
        "id": "rAQTneIXDyO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(sentence,return_tensors='pt')\n",
        "input_ids"
      ],
      "metadata": {
        "id": "_K5j6klIEKJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# generate text util the out put lenght\n",
        "output = model1.generate(input_ids,max_length=50,num_beams=5,no_repeat_ngram_size=2,early_stopping=True) # Fixed typo in variable and method name\n",
        "output"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "M071VwoDKFmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "__mrCbKWJ93i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Greedy Search**"
      ],
      "metadata": {
        "id": "OAvxAE_YM_B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  encode context generation is conditioned on\n",
        "input_ids = tokenizer.encode('python is a very powerfoul computer language',return_tensors='pt')\n",
        "\n",
        "# generate text util the output lenght include the context legth  50\n",
        "greedy_output= model1.generate(input_ids,max_length=50,num_beams=5,no_repeat_ngram_size=2,early_stopping=True)\n",
        "\n",
        "print(\"Output:\\n\" +100 *'-')\n",
        "print(tokenizer.decode(greedy_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "XdpF9dP-LAre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Beam Search**"
      ],
      "metadata": {
        "id": "JvLBmGG5NLF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# activate the beam serch early_stopping\n",
        "beam_output = model1.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\" +100 * '-')\n",
        "print(tokenizer.decode(beam_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "OKuT4U0pNRMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set  no_repeat_ngram_size to 2\n",
        "beam_output = model1.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    early_stopping = True\n",
        ")\n",
        "print(\"Output:\\n\" +100 *'-')\n",
        "print(tokenizer.decode(beam_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "pHTAL9_IOLhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#set return num senquences >1\n",
        "beam_outputs = model1.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_beams=5, # Keep num_beams > 1 for multiple sequences\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_return_sequences=5,\n",
        "    early_stopping=True\n",
        "\n",
        ")\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}:{}\".format(i,tokenizer.decode(beam_output,skip_special_tokens=True)))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8J80iNPGQf9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sampling :**"
      ],
      "metadata": {
        "id": "rTMVo4CNRMR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "#activate sampling and deactive top_k by setting top sampling to 0\n",
        "sample_output = model1.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_k=0\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "print(tokenizer.decode(sample_output[0],skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "KH9mir_QRQjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "#activate sampling and deactive top_k by setting top sampling to 0\n",
        "sample_output = model1.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_k=0,\n",
        "    temperature=0.7\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "print(tokenizer.decode(sample_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "PoJ_jvYCSIbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top K Sampling **"
      ],
      "metadata": {
        "id": "VC36i8hhS9ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "# set top K to 50\n",
        "sample_output = model1.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_k=50\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "print(tokenizer.decode(sample_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "MgR62yIhTDZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top P sampling **"
      ],
      "metadata": {
        "id": "2zsKU83TTj93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "# deactivate  top_k sampling and sample only from 92% most likely words\n",
        "sample_output = model1.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_p=0.92,\n",
        "    top_k=0\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "print(tokenizer.decode(sample_output[0],skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "JVhpIO4-TnEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "# set top_k  = 50 and set top_p= 0.95 and num return sequences = 3\n",
        "sample_output = model1.generate(\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_k=0,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=3\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}:{}\".format(i,tokenizer.decode(sample_output,skip_special_tokens=True)))\n"
      ],
      "metadata": {
        "id": "-MNvAj8gUFne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# set see to reproduce results. feels free to change the seed though to get different results.\n",
        "tf.random.set_seed(0)\n",
        "# set top_k  = 50 and set top_p= 0.95 and num return sequences = 3\n",
        "sample_outputs = model1.generate( # changed variable name to sample_outputs\n",
        "    input_ids,\n",
        "    do_sample=True,\n",
        "    max_length=50,\n",
        "    top_k=0,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=3\n",
        "\n",
        ")\n",
        "print(\"Output:\\n\"+100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}:{}\".format(i,tokenizer.decode(sample_output,skip_special_tokens=True)))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fGjqvZk-WIIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lBtmSa00VidH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}